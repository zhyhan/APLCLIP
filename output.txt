./logs
Environment:
	Python: 3.11.3
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.3
	PIL: 9.5.0
Args:
	algorithm: CoCoOpCLIP
	checkpoint_freq: None
	data_dir: /home/zhongyi.han/dataset
	dataset: VLCS
	holdout_fraction: 0.2
	hparams: {"clip_backbone": "ViT-B/16"}
	hparams_seed: 0
	output_dir: ./logs
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	backbone: clip
	batch_size: 32
	class_balanced: False
	clip_backbone: ViT-B/16
	clip_transform: True
	data_augmentation: True
	lr: 5e-05
	mlp_depth: 3
	mlp_dropout: 0.1
	mlp_width: 512
	momentum: 0.1
	nonlinear_classifier: False
	num_domain_tokens: 16
	resnet18: False
	resnet_dropout: 0.0
	test_envs: [0]
	weight_decay: 0.0
Using clip_transform ViT-B/16
Set self.clip_model.parameters.reguires_grad = False!
Set self.clip_model.parameters.reguires_grad = False!
Initial context: "a photo of a"
Number of context words (tokens): 4
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          step          step_time    
0.5600706714  0.5653710247  0.4117647059  0.3992467043  0.5099009901  0.4893292683  0.5494261385  0.5377777778  0.0000000000  1.3760367632  0             3.0747578144 
0.7614840989  0.7455830389  0.5731764706  0.5536723164  0.6207159177  0.5807926829  0.6323583858  0.6562962963  8.4805653710  0.7919628300  300           0.4437368202 
0.8206713781  0.8056537102  0.5948235294  0.5894538606  0.6325209444  0.5884146341  0.6590151796  0.6888888889  16.961130742  0.6573661895  600           0.4451538436 
0.8489399293  0.8445229682  0.6051764706  0.6158192090  0.6439451637  0.6082317073  0.6775268419  0.7081481481  25.441696113  0.6304748643  900           0.4370550410 
0.8701413428  0.8798586572  0.6207058824  0.6139359699  0.6538461538  0.6280487805  0.6915957053  0.7259259259  33.922261484  0.6116706348  1200          0.4402727890 
0.9028268551  0.8975265018  0.6338823529  0.6252354049  0.6656511805  0.6493902439  0.7145501666  0.7318518519  42.402826855  0.6042753930  1500          0.4396988312 
0.9169611307  0.9081272085  0.6550588235  0.6421845574  0.6782178218  0.6722560976  0.7282487967  0.7496296296  50.883392226  0.5935157572  1800          0.4383070954 
0.9293286219  0.9151943463  0.6583529412  0.6516007533  0.6862147753  0.6783536585  0.7345427619  0.7525925926  59.363957597  0.5856123381  2100          0.4390215890 
0.9346289753  0.9187279152  0.6635294118  0.6629001883  0.6911652704  0.6814024390  0.7382450944  0.7540740741  67.844522968  0.5780590340  2400          0.4382510877 
0.9372791519  0.9222614841  0.6672941176  0.6647834275  0.6980198020  0.6829268293  0.7445390596  0.7600000000  76.325088339  0.5629629481  2700          0.4460424081 
0.9363957597  0.9293286219  0.6701176471  0.6741996234  0.6991622239  0.6814024390  0.7437985931  0.7644444444  84.805653710  0.5641348299  3000          0.4408245047 
0.9390459364  0.9257950530  0.6720000000  0.6723163842  0.6999238385  0.6875000000  0.7482413921  0.7688888889  93.286219081  0.5612948867  3300          0.4312407978 
0.9408127208  0.9293286219  0.6743529412  0.6817325800  0.7041127190  0.6890243902  0.7515734913  0.7762962963  101.76678445  0.5545234728  3600          0.4422986118 
0.9416961131  0.9293286219  0.6748235294  0.6817325800  0.7044935263  0.6905487805  0.7512032581  0.7733333333  110.24734982  0.5591427666  3900          0.4464870334 
0.9425795053  0.9363957597  0.6743529412  0.6836158192  0.7075399848  0.6905487805  0.7530544243  0.7733333333  118.72791519  0.5543321248  4200          0.4433058794 
0.9434628975  0.9399293286  0.6734117647  0.6854990584  0.7105864433  0.6890243902  0.7512032581  0.7718518519  127.20848056  0.5563286760  4500          0.4438060435 
0.9434628975  0.9469964664  0.6729411765  0.6836158192  0.7090632140  0.6890243902  0.7530544243  0.7762962963  135.68904593  0.5482026912  4800          0.4446667560 
0.9443462898  0.9469964664  0.6734117647  0.6854990584  0.7113480579  0.6920731707  0.7545353573  0.7733333333  141.34275618  0.5336151531  5000          0.4454899967 
