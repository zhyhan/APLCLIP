WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py:187: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  torch.nn.init.xavier_uniform(m.weight)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 213, in update
    _mean_domain_features = [feature.repeat_interleave(len(self.hparams['class_names']), dim=0) for feature in mean_domain_features]
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 213, in <listcomp>
    _mean_domain_features = [feature.repeat_interleave(len(self.hparams['class_names']), dim=0) for feature in mean_domain_features]
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py:189: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  torch.nn.init.xavier_uniform(m.weight)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 215, in update
    _mean_domain_features = [feature.repeat_interleave(len(self.hparams['class_names']), dim=0) for feature in mean_domain_features]
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 215, in <listcomp>
    _mean_domain_features = [feature.repeat_interleave(len(self.hparams['class_names']), dim=0) for feature in mean_domain_features]
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py:190: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  torch.nn.init.xavier_uniform(m.weight)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 228, in update
    loss.backward()
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 183, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 157, in __init__
    super(DPLCLIP, self).__init__(input_shape, num_classes, num_domains, hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 132, in __init__
    self.clip_model = clip.load(self.hparams['clip_backbone'])[0].float()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/clip.py", line 139, in load
    model = build_model(state_dict or model.state_dict()).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 434, in build_model
    convert_weights(model)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 396, in convert_weights
    model.apply(_convert_weights_to_fp16)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 884, in apply
    module.apply(fn)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 884, in apply
    module.apply(fn)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 884, in apply
    module.apply(fn)
  [Previous line repeated 3 more times]
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 885, in apply
    fn(self)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 380, in _convert_weights_to_fp16
    l.weight.data = l.weight.data.half()
                    ^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 229, in <module>
    for x,y in next(train_minibatches_iterator)]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/fast_data_loader.py", line 43, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1295, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
         ^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 507, in Client
    answer_challenge(c, authkey)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 751, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 215, in recv_bytes
    buf = self._recv_bytes(maxlength)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 413, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 378, in _recv
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 228, in <module>
    minibatches_device = [(x.to(device), y.to(device))
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 228, in <listcomp>
    minibatches_device = [(x.to(device), y.to(device))
                           ^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 228, in update
    loss.backward()
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 208, in update
    print(image_features.shape())
          ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'shape'
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 235, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 213, in update
    mean_domain_features = [feature.mean(dim=0, keepdim=True) for feature in domain_features]
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'torch.Size' object is not callable
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 252, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 115, in accuracy
    for x, y in loader:
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/fast_data_loader.py", line 70, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1295, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 252, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 118, in accuracy
    p = network.predict(x)
        ^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 255, in predict
    mean_domain_feature = torch.mean(domain_feature, dim=0, keepdim=True).repeat_interleave(len(self.hparams['class_names']), dim=0)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 252, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 115, in accuracy
    for x, y in loader:
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/fast_data_loader.py", line 70, in __iter__
    yield next(self._infinite_iterator)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1295, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 190, in <module>
    algorithm.to(device)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1145, in to
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 338, in update
    return {'disc_loss': disc_loss.item()}
                         ^^^^^^^^^^^^^^^^
KeyboardInterrupt
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 307, in update
    all_z = self.featurizer(all_x)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/networks.py", line 256, in forward
    return self.clip_model.encode_image(x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 341, in encode_image
    return self.visual(image.type(self.dtype))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 232, in forward
    x = self.transformer(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 203, in forward
    return self.resblocks(x)
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 191, in forward
    x = x + self.mlp(self.ln_2(x))
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.62 GiB total capacity; 5.79 GiB already allocated; 106.25 MiB free; 5.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 307, in update
    all_z = self.featurizer(all_x)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/networks.py", line 256, in forward
    return self.clip_model.encode_image(x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 341, in encode_image
    return self.visual(image.type(self.dtype))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 232, in forward
    x = self.transformer(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 203, in forward
    return self.resblocks(x)
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 191, in forward
    x = x + self.mlp(self.ln_2(x))
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.62 GiB total capacity; 5.79 GiB already allocated; 106.25 MiB free; 5.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 110, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 214, in __init__
    clip_transform = clip.load(hparams['clip_backbone'])[1]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/clip.py", line 129, in load
    model = torch.jit.load(opened_file, map_location=device if jit else "cpu").eval()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/jit/_serialization.py", line 165, in load
    cu, f.read(), map_location, _extra_files, _restore_shapes
        ^^^^^^^^
KeyboardInterrupt
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 253, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 124, in accuracy
    batch_weights = batch_weights.to(device)
                    ^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 110, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 213, in __init__
    print('Using clip_transform', hparams['clip_backbone'])
                                  ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'clip_backbone'
Exception ignored in: <module 'threading' from '/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/threading.py'>
Traceback (most recent call last):
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/threading.py", line 1583, in _shutdown
    lock.acquire()
KeyboardInterrupt: 
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 110, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 213, in __init__
    print('Using clip_transform', hparams['clip_backbone'])
                                  ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'clip_backbone'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 236, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 307, in update
    all_z = self.featurizer(all_x)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/networks.py", line 256, in forward
    return self.clip_model.encode_image(x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 341, in encode_image
    return self.visual(image.type(self.dtype))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 232, in forward
    x = self.transformer(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 203, in forward
    return self.resblocks(x)
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 191, in forward
    x = x + self.mlp(self.ln_2(x))
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.62 GiB total capacity; 5.79 GiB already allocated; 105.75 MiB free; 5.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 183, in <module>
    algorithm_class = algorithms.get_algorithm_class(args.algorithm)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 40, in get_algorithm_class
    raise NotImplementedError("Algorithm not found: {}".format(algorithm_name))
NotImplementedError: Algorithm not found: CLPS
WARNING:root:The WILDS package is out of date. Your version is 1.2.2, while the latest version is 2.0.0.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 164, in __init__
    self.prompt_generator = CoCoOpPromptLearner()
                            ^^^^^^^^^^^^^^^^^^^^^
TypeError: CoCoOpPromptLearner.__init__() missing 4 required positional arguments: 'input_shape', 'num_classes', 'num_domains', and 'hparams'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 164, in __init__
    self.prompt_generator = CoCoOpPromptLearner(input_shape, num_classes, num_domains, hparams)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 228, in __init__
    super(DPLCLIP, self).__init__(input_shape, num_classes, num_domains, hparams)
    ^^^^^^^^^^^^^^^^^^^^
TypeError: super(type, obj): obj must be an instance or subtype of type
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 166, in __init__
    self.dtype = self.clip.dtype
                 ^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CoCoOpCLIP' object has no attribute 'clip'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 166, in __init__
    self.dtype = self.clip.dtype
                 ^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CoCoOpCLIP' object has no attribute 'clip'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 169, in __init__
    [self.prompt_generator.meta_net.parameters(), self.prompt_generator.ctx.parameters()],
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Parameter' object has no attribute 'parameters'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 171, in __init__
    momentum=self.hparams["momentum"]
             ~~~~~~~~~~~~^^^^^^^^^^^^
KeyError: 'momentum'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 83, in <module>
    hparams = hparams_registry.default_hparams(args.algorithm, args.dataset)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/hparams_registry.py", line 147, in default_hparams
    _hparams(algorithm, dataset, 0).items()}
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/hparams_registry.py", line 107, in _hparams
    _hparam('weight_decay', 0., lambda r: 0.)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/hparams_registry.py", line 21, in _hparam
    assert(name not in hparams)
           ^^^^^^^^^^^^^^^^^^^
AssertionError
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 168, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 512, in add_param_group
    raise TypeError("optimizer can only optimize Tensors, "
TypeError: optimizer can only optimize Tensors, but one of the params is Module.parameters
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 237, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 175, in update
    all_x = [data[0].cuda().float() for data in minibatches]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 175, in <listcomp>
    all_x = [data[0].cuda().float() for data in minibatches]
             ^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/cuda/__init__.py", line 247, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 168, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 512, in add_param_group
    raise TypeError("optimizer can only optimize Tensors, "
TypeError: optimizer can only optimize Tensors, but one of the params is torch.nn.modules.container.Sequential
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 169, in __init__
    (list(self.prompt_generator.meta_net.parameters()) + self.prompt_generator.ctx),
     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~
TypeError: can only concatenate list (not "Parameter") to list
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 168, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 169, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 169, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 169, in __init__
    self.prompt_generator.meta_net.parameters().requires_grad = True
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'generator' object has no attribute 'requires_grad'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 170, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 175, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 512, in add_param_group
    raise TypeError("optimizer can only optimize Tensors, "
TypeError: optimizer can only optimize Tensors, but one of the params is Module.parameters
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 175, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 512, in add_param_group
    raise TypeError("optimizer can only optimize Tensors, "
TypeError: optimizer can only optimize Tensors, but one of the params is Module.parameters
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 164, in __init__
    self.prompt_generator = CoCoOpPromptLearner(input_shape, num_classes, num_domains, hparams)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 260, in __init__
    self.meta_net = nn.Sequential([
                    ^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 104, in __init__
    self.add_module(str(idx), module)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 596, in add_module
    raise TypeError("{} is not a Module subclass".format(
TypeError: list is not a Module subclass
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 164, in __init__
    self.prompt_generator = CoCoOpPromptLearner(input_shape, num_classes, num_domains, hparams)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 260, in __init__
    self.meta_net = nn.Sequential(
                    ^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 104, in __init__
    self.add_module(str(idx), module)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 596, in add_module
    raise TypeError("{} is not a Module subclass".format(
TypeError: tuple is not a Module subclass
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 237, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in update
    all_x = [data[0].self.device().float() for data in minibatches]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in <listcomp>
    all_x = [data[0].self.device().float() for data in minibatches]
             ^^^^^^^^^^^^
AttributeError: 'Tensor' object has no attribute 'self'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 170, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 170, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 192, in __init__
    self.add_param_group(param_group)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 515, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 185, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 175, in __init__
    self.optimizer = torch.optim.SGD(
                     ^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/sgd.py", line 27, in __init__
    super().__init__(params, defaults)
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/optim/optimizer.py", line 178, in __init__
    raise TypeError("params argument given to the optimizer should be "
TypeError: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 237, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in update
    all_x = [data[0].self.device().float() for data in minibatches]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in <listcomp>
    all_x = [data[0].self.device().float() for data in minibatches]
             ^^^^^^^^^^^^
AttributeError: 'Tensor' object has no attribute 'self'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 237, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in update
    all_x = [data[0].self.device().float() for data in minibatches]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 182, in <listcomp>
    all_x = [data[0].self.device().float() for data in minibatches]
             ^^^^^^^^^^^^
AttributeError: 'Tensor' object has no attribute 'self'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 237, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 192, in update
    ctx = ctx.permute(1, 0, 2, 3)
          ^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 254, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 118, in accuracy
    p = network.predict(x)
        ^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 227, in predict
    domain_feature = self.network(image_feature)
                     ^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CoCoOpCLIP' object has no attribute 'network'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 254, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/lib/misc.py", line 118, in accuracy
    p = network.predict(x)
        ^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/algorithms.py", line 223, in predict
    image_feature = self.clip_model.encode_image(x)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 341, in encode_image
    return self.visual(image.type(self.dtype))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 232, in forward
    x = self.transformer(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 203, in forward
    return self.resblocks(x)
           ^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 190, in forward
    x = x + self.attention(self.ln_1(x))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/clip/model.py", line 187, in attention
    return self.attn(x, x, x, need_weights=False, attn_mask=self.attn_mask)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 1189, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/functional.py", line 5188, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/.conda/envs/CLIP/lib/python3.11/site-packages/torch/nn/functional.py", line 4765, in _in_projection_packed
    proj = linear(q, w, b)
           ^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 111, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 213, in __init__
    print('Using clip_transform', hparams['clip_backbone'])
                                  ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'clip_backbone'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 111, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 213, in __init__
    print('Using clip_transform', hparams['clip_backbone'])
                                  ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'clip_backbone'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/zhongyi.han/project/APLCLIP/domainbed/scripts/train.py", line 111, in <module>
    dataset = vars(datasets)[args.dataset](args.data_dir, args.test_envs, hparams)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 240, in __init__
    super().__init__(self.dir, test_envs, hparams['data_augmentation'], hparams)
  File "/home/zhongyi.han/project/APLCLIP/domainbed/datasets.py", line 213, in __init__
    print('Using clip_transform', hparams['clip_backbone'])
                                  ~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'clip_backbone'
